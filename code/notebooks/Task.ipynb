{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача про джоин\n",
    "\n",
    "Входные данные:\n",
    "    1 - кликстрим (= поток фактов), нарезанный файлами, например csv.gz, первая колонка - ID пользователя (тип UUID), country_iso3_code - код страны по iso 3-х буквенный, остальные - не принципиально, но например event_name - строка, event_tms - unixtime \n",
    "    2 - дименшен с аттрибутами пользователя в какой-нибудть СУБД или опять же в csv; колонки ID, install_tms  (10+M записей)\n",
    "\n",
    "На выходе хотим видеть (например в csv) данные в виде:\n",
    "    ID,country_iso2_code (ISO 3166-1 alpha-2),install_tms,event_name,event_tms\n",
    "    \n",
    "Пожелания к решению:\n",
    "    1 - Хотелось бы чтобы код умел работать эффективно как в случае когда у нас много (= неограничено) памяти, так и в случае если у нас есть верхний лимит N_bytes\n",
    "    2 - Хотелось бы чтобы можно было распараллелить процесс ↑ на несколько ядер одного процессора (или в пределе - на другие машины)\n",
    "    3 - базовый стек shell, python, psql, clickhouse; но не возбраняется использовать доп. средства (либы, пакеты, платформы, СУБД, ...) если есть необходимость"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/code')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask.delayed import delayed\n",
    "from dask.distributed import Client\n",
    "from os import environ\n",
    "from task_generate_data import generate_data, DB_NAME, TABLE_NAME, CLCKSTREAM_NAME\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_HOST = environ[\"DB_HOST\" ]\n",
    "DASK_SCHEDULER_ADDRESS = environ[\"DASK_SCHEDULER_ADDRESS\"]\n",
    "DATA_DIR = environ[\"TASK_DATA_DIR\"]\n",
    "RESULT_DIR = environ[\"RESULT_DATA_DIR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_uri = f\"postgresql://postgres:postgres@{DB_HOST}:5432/{DB_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "client = Client(\"tcp://scheduler:8786\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask дашборд: (http://127.0.0.1:8787)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбор dask продиктован необходимостью уметь масштабироваться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Эта команда:\n",
    "#   Создаст базу данных вместе с таблицами\n",
    "#   Сгенерирует фейковые данные в CSV и загрузит их в базу\n",
    "\n",
    "generate_data(total_users=1000000,\n",
    "              clickstream_file_max_lines=1000000,\n",
    "              events_per_user=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запрос для чтения данных из БД"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подразумевается, что данные в таблице не изменяются за период чтения. Если это не так, то необходимо предусмотреть дополнительную логику."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = f\"\"\"\n",
    "select t.*\n",
    "from {TABLE_NAME} as t\n",
    "         left join (\n",
    "    select user_id, ntile({{pages_total}}) over (order by user_id) as page\n",
    "    from {TABLE_NAME}\n",
    ") as p on p.user_id = t.user_id\n",
    "where p.page = {{page}};\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Источник 1 - БД"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерируем lazy-load computations для dask. Используем .persist() для избежания повторных чтений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pages = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dimensions = dd.from_delayed([\n",
    "    delayed(pd.read_sql_query)(QUERY.format(pages_total=total_pages, page=page+1), pg_uri)\n",
    "    for page in range(total_pages)\n",
    "]).persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Источник 2 - CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clickstream = dd.read_csv(f'{DATA_DIR}/{CLCKSTREAM_NAME}*.csv.gz', \n",
    "                             compression='gzip',\n",
    "                             blocksize=None,\n",
    "                             header=None,\n",
    "                             names=['user_id', 'country_iso3_code', 'event_type', 'event_tms']\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Источник 3 - Коды стран"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_countries = pd.read_csv('https://raw.githubusercontent.com/datasets/country-codes/master/data/country-codes.csv', keep_default_na=False)\n",
    "df_countries = df_countries[['ISO3166-1-Alpha-3', 'ISO3166-1-Alpha-2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Джойним источники"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (    \n",
    "    df_dimensions\n",
    "    .merge(df_clickstream, how='left', on='user_id')\n",
    "    .merge(df_countries, how='left', left_on='country_iso3_code', right_on='ISO3166-1-Alpha-3')\n",
    "    .rename(columns={\"ISO3166-1-Alpha-2\": \"country_iso2_code\"})\n",
    "    \n",
    ")\n",
    "df=df[[\"user_id\", \"country_iso2_code\", \"install_tms\", \"event_type\", \"event_tms\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(RESULT_DIR / Path('export-*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "head /result_data/export-00.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
